{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWyN_AlQwHnR",
        "outputId": "adebdd96-fa69-499a-8412-c5e2e0544003"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n",
            "Collecting openai\n",
            "  Downloading openai-1.23.6-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.6/311.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.1)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.23.6\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.1.16-py3-none-any.whl (817 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.5-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.32 (from langchain)\n",
            "  Downloading langchain_community-0.0.34-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.42 (from langchain)\n",
            "  Downloading langchain_core-0.1.46-py3-none-any.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.3/299.3 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.52-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.4/116.4 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.42->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.5 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.16 langchain-community-0.0.34 langchain-core-0.1.46 langchain-text-splitters-0.0.1 langsmith-0.1.52 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.10.1 packaging-23.2 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install python-dotenv\n",
        "!pip install openai\n",
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8wlhgijwPin"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "openai.api_key = \"***YOUR_OPENAI_KEY***\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxYzuOdxU4NM"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.simplefilter('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7C0fxhwZwUBX"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain import OpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain.schema import SystemMessage\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import (\n",
        "    PromptTemplate,\n",
        "    ChatPromptTemplate,\n",
        "    StringPromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        "    BaseChatPromptTemplate\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyY5l3HfYGGx",
        "outputId": "995156a9-e905-41ec-e94c-26aa3db150f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.0-py3-none-any.whl (56 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/56.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (9.4.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.29.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (42.0.5)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Installing collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.0 pypdfium2-4.29.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pdfplumber"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfYy2BInWHtr"
      },
      "outputs": [],
      "source": [
        "import pdfplumber"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "-Ifnq96rPI-E",
        "outputId": "3755297f-7bd6-4bcb-a68b-b199ac9422c2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-78f7f4c0-a7ae-449c-98ae-7a5d34f059ea\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-78f7f4c0-a7ae-449c-98ae-7a5d34f059ea\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Flights VoyagerAIr.pdf to Flights VoyagerAIr.pdf\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cQcRDrtXd8Q",
        "outputId": "d48a3831-2f73-4008-9073-23931ac9a1be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Origin DestinationDate Time Class Price Airline\n",
            "London, Paris,\n",
            "UK France 6/1/2024 10:00 Economy 150VoyagerAIr\n",
            "London, Paris,\n",
            "UK France 6/1/2024 10:00 Business 150VoyagerAIr\n",
            "London, Paris,\n",
            "UK France 6/8/2024 10:00 Economy 150VoyagerAIr\n",
            "London, Paris,\n",
            "UK France 6/8/2024 10:00 Business 150VoyagerAIr\n",
            "London, Paris,\n",
            "UK France 6/15/202410:00 Economy 150VoyagerAIr\n",
            "London, Paris,\n",
            "UK France 6/15/202410:00 Business 150VoyagerAIr\n",
            "London, Paris,\n",
            "UK France 6/22/202410:00 Economy 150VoyagerAIr\n",
            "London, Paris,\n",
            "UK France 6/22/202410:00 Business 150VoyagerAIr\n",
            "London, Paris,\n",
            "UK France 6/29/202410:00 Economy 150VoyagerAIr\n",
            "London, Paris,\n",
            "UK France 6/29/202410:00 Business 150VoyagerAIr\n",
            "Paris, London,\n",
            "France UK 6/1/2024 17:00 Economy 150VoyagerAIr\n",
            "Paris, London,\n",
            "France UK 6/1/2024 17:00 Business 150VoyagerAIr\n",
            "Paris, London,\n",
            "France UK 6/8/2024 17:00 Economy 150VoyagerAIr\n",
            "Paris, London,\n",
            "France UK 6/8/2024 17:00 Business 150VoyagerAIr\n",
            "Paris, London,\n",
            "France UK 6/15/202417:00 Economy 150VoyagerAIr\n",
            "Paris, London,\n",
            "France UK 6/15/202417:00 Business 150VoyagerAIr\n",
            "Paris, London,\n",
            "France UK 6/22/202417:00 Economy 150VoyagerAIr\n",
            "Paris, London,\n",
            "France UK 6/22/202417:00 Business 155VoyagerAIr\n",
            "Paris, London,\n",
            "France UK 6/29/202417:00 Economy 150VoyagerAIr\n",
            "Paris, London,\n",
            "France UK 6/29/202417:00 Business 155VoyagerAIr\n",
            "London, Rome,\n",
            "UK Italy 6/2/2024 10:00 Economy 200VoyagerAIr\n",
            "London, Rome,\n",
            "UK Italy 6/2/2024 10:00 Business 225VoyagerAIr\n",
            "London, Rome,\n",
            "UK Italy 6/9/2024 10:00 Economy 200VoyagerAIr\n",
            "London, Rome,\n",
            "UK Italy 6/9/2024 10:00 Business 225VoyagerAIr\n",
            "London, Rome,\n",
            "UK Italy 6/16/202410:00 Economy 200VoyagerAIr\n",
            "London, Rome,\n",
            "UK Italy 6/16/202410:00 Business 225VoyagerAIr\n",
            "London, Rome,\n",
            "UK Italy 6/23/202410:00 Economy 200VoyagerAIr\n",
            "London, Rome,\n",
            "UK Italy 6/23/202410:00 Business 225VoyagerAIr\n",
            "London, Rome,\n",
            "UK Italy 6/30/202410:00 Economy 200VoyagerAIr\n",
            "London, Rome,\n",
            "UK Italy 6/30/202410:00 Business 225VoyagerAIr\n",
            "Rome, London,\n",
            "Italy UK 6/2/2024 17:00 Economy 200VoyagerAIr\n",
            "Rome, London,\n",
            "Italy UK 6/2/2024 17:00 Business 225VoyagerAIr\n",
            "Rome, London,\n",
            "Italy UK 6/9/2024 17:00 Economy 200VoyagerAIr\n",
            "Rome, London,\n",
            "Italy UK 6/9/2024 17:00 Business 225VoyagerAIr\n",
            "Rome, London,\n",
            "Italy UK 6/16/202417:00 Economy 200VoyagerAIr\n",
            "Rome, London,\n",
            "Italy UK 6/16/202417:00 Business 225VoyagerAIr\n",
            "Rome, London,\n",
            "Italy UK 6/23/202417:00 Economy 200VoyagerAIr\n",
            "Rome, London,\n",
            "Italy UK 6/23/202417:00 Business 225VoyagerAIr\n",
            "Rome, London,\n",
            "Italy UK\n",
            "6/30/202417:00 Economy 200VoyagerAIr\n",
            "Rome, London,\n",
            "Italy UK 6/30/202417:00 Business 225VoyagerAIr\n",
            "London, Berlin,\n",
            "UK Germany 6/2/2024 10:00 Economy 90VoyagerAIr\n",
            "London, Berlin,\n",
            "UK Germany 6/2/2024 10:00 Business 100VoyagerAIr\n",
            "London, Berlin,\n",
            "UK Germany 6/9/2024 10:00 Economy 90VoyagerAIr\n",
            "London, Berlin,\n",
            "UK Germany 6/9/2024 10:00 Business 100VoyagerAIr\n",
            "London, Berlin,\n",
            "UK Germany 6/16/202410:00 Economy 90VoyagerAIr\n",
            "London, Berlin,\n",
            "UK Germany 6/16/202410:00 Business 100VoyagerAIr\n",
            "London, Berlin,\n",
            "UK Germany 6/23/202410:00 Economy 90VoyagerAIr\n",
            "London, Berlin,\n",
            "UK Germany 6/23/202410:00 Business 100VoyagerAIr\n",
            "London, Berlin,\n",
            "UK Germany 6/30/202410:00 Economy 90VoyagerAIr\n",
            "London, Berlin,\n",
            "UK Germany 6/30/202410:00 Business 100VoyagerAIr\n",
            "Berlin, London,\n",
            "GermanyUK 6/2/2024 10:00 Economy 90VoyagerAIr\n",
            "Berlin, London,\n",
            "GermanyUK 6/2/2024 10:00 Business 100VoyagerAIr\n",
            "Berlin, London,\n",
            "GermanyUK 6/9/2024 10:00 Economy 90VoyagerAIr\n",
            "Berlin, London,\n",
            "GermanyUK 6/9/2024 10:00 Business 100VoyagerAIr\n",
            "Berlin, London,\n",
            "GermanyUK 6/16/202410:00 Economy 90VoyagerAIr\n",
            "Berlin, London,\n",
            "GermanyUK 6/16/202410:00 Business 100VoyagerAIr\n",
            "Berlin, London,\n",
            "GermanyUK 6/23/202410:00 Economy 90VoyagerAIr\n",
            "Berlin, London,\n",
            "GermanyUK 6/23/202410:00 Business 100VoyagerAIr\n",
            "Berlin, London,\n",
            "GermanyUK 6/30/202410:00 Economy 90VoyagerAIr\n",
            "Berlin, London,\n",
            "GermanyUK 6/30/202410:00 Business 100VoyagerAIr\n",
            "London, Rome,\n",
            "UK Italy 6/2/2024 17:00 Economy 200VoyagerAIr\n",
            "London, Rome,\n",
            "UK Italy 6/2/2024 17:00 Business 225VoyagerAIr\n",
            "London, Rome,\n",
            "UK Italy 6/9/2024 17:00 Economy 200VoyagerAIr\n",
            "London, Rome,\n",
            "UK Italy 6/9/2024 17:00 Business 225VoyagerAIr\n",
            "London, Rome,\n",
            "UK Italy 6/16/202417:00 Economy 200VoyagerAIr\n",
            "London, Rome,\n",
            "UK Italy 6/16/202417:00 Business 225VoyagerAIr\n",
            "London, Rome,\n",
            "UK Italy 6/23/202417:00 Economy 200VoyagerAIr\n",
            "London, Rome,\n",
            "UK Italy 6/23/202417:00 Business 225VoyagerAIr\n",
            "London, Rome,\n",
            "UK Italy 6/30/202417:00 Economy 200VoyagerAIr\n",
            "London, Rome,\n",
            "UK Italy 6/30/202417:00 Business 225VoyagerAIr\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "document = \"\"\n",
        "with pdfplumber.open(\"/content/Flights VoyagerAIr.pdf\") as pdf:\n",
        "            for page in pdf.pages:\n",
        "                text = page.extract_text(x_tolerance=1)\n",
        "                print(text)\n",
        "                document += text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peX1tdwrYrTP"
      },
      "outputs": [],
      "source": [
        "prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "\n",
        "You are a travel bot called VoyagerAI. You are friendly and helpful. You give clear and concise information. You talk in daily language and avoid using uncommon words. \\\n",
        "Your primary mission is to help the customers plan and optimize their travel experiences. Keep your answers to a maximum of 90 characters long.\\\n",
        "If you are listing examples, flights, services, etc., then you can omit the character counts for these from your message limit.\n",
        "\n",
        "A list of how you assist the customers:\\\n",
        "\n",
        "1. Destination Inspiration: you suggest destinations based on their preferences, such as climate, activities (beach, hiking, cultural experiences), budget, and travel dates.\\\n",
        "\n",
        "2. Trip Planning: You help the customers plan their itinerary. This would include recommending sights to see, activities to do, places to eat, and where to stay.\\\n",
        "The itineraries should include details like travel times between locations, opening hours, and recommended time to spend at each place.\\\n",
        "Do not give more than 3 recommendations unless specifically requested, in which case limit your recommendations to 8.\\\n",
        "For each recommendation, limit the characters to a maximum of 50 characters.\\\n",
        "\n",
        "If the customer asks for a plan for her/his trip, you ask the budget of the customer, \\\n",
        "After you get the budget information, ask her/his interests, who she/he will travel with, and if she/he has a special need.\\\n",
        "\n",
        "3. Booking Assistance: you guide the customers through booking flights, accommodation, and activities, or direct them to the best websites and services for making these bookings.\\\n",
        "\n",
        "You only book flights through {document}\n",
        "If the customer wants to book a flight, Search this flight document for VoyagerAI: {document}, list the flights from the origin to destination with date, class, price, and airline information.\\\n",
        "If there is a suitable flight according to the customers preference, let the customers know the assistant will book their flight in a minute.\\\n",
        "Meanwhile ask the customer if she/he needs recommendation about the itenary. \\\n",
        "\n",
        "    Customer: I want to book a flight to Berlin to London. Can you help me with that?\n",
        "    VoyagerAI:\n",
        "    Action Search {document}\n",
        "    Observation There are number of flights I can recommend.\n",
        "    Thought I need to recommend all of the suitable flights and later ask about the itenary.\n",
        "\n",
        "    -If there are no flights suitable for their origin and destination, suggest other sources to book the flight tickets.\\\n",
        "\n",
        "    Customer: I want to book a flight to Edinburgh Airport.\n",
        "    VoyagerAI: Where will you be your origin?\n",
        "    Customer: London\n",
        "    VoyagerAI:\n",
        "    Action Search {document}\n",
        "    Observation There are no flights from London to Edinburgh in [document]\n",
        "    Thought I need to let the customer know that there are no flights in VoyagerAIr and direct she/he to another website.\n",
        "\n",
        "4. Travel Tips: You provide customers with travel tips, such as what to pack, cultural norms of your destination, and how to navigate local transportation.\\\n",
        "\n",
        "5. Local Insights and Tips: You give insights into local events, festivals, or off-the-beaten-path attractions, and how to stay safe in different destinations,\\\n",
        "the dress code and cultural etiquette that might enrich the customers travel experience.\\\n",
        "\n",
        "6. Real-time Assistance: You give real-time support for travelers on the go, such as help with navigation, finding nearby attractions, or answering common travel-related questions.\\\n",
        "\n",
        "7. Emergency Services: You give quick access to emergency numbers, embassy information, and other essential services for the customers in distress should they require or enquire about it.\\\n",
        "\n",
        "8. Sustainability Options: You provide one brief eco-friendly travel, accommodation, or activity option/suggestion for any list of suggestions or recommendations related to travel, accommodation, or activities.\\\n",
        "\n",
        "---\n",
        "\n",
        "You start by greeting the customer. Do not forget to state your name. List the names of the services you provide in list form and ask how you can assist the customer.\\\n",
        "\n",
        "Then, you ask for the destination. If the customer has not set a destination yet, you assist with \"destination inspiration\".\\\n",
        "After learning the destination, or setting a destination, provide the service the customer asks.\\\n",
        "If no service is requested, determine the customer's travel dates, budget, and origin one at a time.\\\n",
        "\n",
        "If the customer does not provide the answers to these questions, respect their privacy and do not ask again.\\\n",
        "\n",
        "With the information you have, start planning the trip according to \"Trip planning\"\\\n",
        "\n",
        "This is an interactive dialogue, so keep your answers short. Ask if the customer needs more assistance after every answer. \\\n",
        "\n",
        "Current conversation:\n",
        "{history}\n",
        "\n",
        "User: {human_input}\n",
        "Chatbot: \"\"\n",
        "\"\"\",\n",
        "input_variables=[\"reco\", \"history\", \"human_input\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oL2t9cLP_Ol"
      },
      "outputs": [],
      "source": [
        "prompt_formatted_str: str = prompt.format(\n",
        "    document=document,\n",
        "    history=\"{history}\",\n",
        "    human_input=\"{human_input}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrM2SFFFYPIZ"
      },
      "outputs": [],
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables= [\"history\", \"human_input\"],\n",
        "    template=prompt_formatted_str\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1OCGEdpJqK1"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(openai_api_key=\"**YOUR OPENAI API KEY\", model=\"gpt-4-0125-preview\", temperature=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaeGNp-pfEbc"
      },
      "outputs": [],
      "source": [
        "memory = ConversationBufferWindowMemory(\n",
        "    memory_key=\"history\", k=5, return_messages=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XExwoiwPfEU6"
      },
      "outputs": [],
      "source": [
        "chat_llm_chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=prompt,\n",
        "    memory=memory,\n",
        "    verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMMJelOVP29w"
      },
      "outputs": [],
      "source": [
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Au8cHH8kfvK9"
      },
      "outputs": [],
      "source": [
        "uniq_filename = \"Dialogue\" + '_' + str(datetime.datetime.now().isoformat(sep=\"_\", timespec=\"seconds\")).replace(':', '-') + \".txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QZqPu-8f3P8"
      },
      "outputs": [],
      "source": [
        "path = \"/content/\"\n",
        "Dfile = open(os.path.join (path, uniq_filename), \"a\") # the 'a' means you are adding to the file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrZH5QYdf6Yx"
      },
      "outputs": [],
      "source": [
        "# You need to click again on 'play' to STOP the dialogue (otherwise it won't be saved)\n",
        "#\n",
        "# to talk, just enter your utterance in the box and press 'ENTER'\n",
        "#\n",
        "i = 0\n",
        "while True:\n",
        "    try:\n",
        "        i = i + 1\n",
        "        # Get user input\n",
        "        user_input = input(\"User > \")\n",
        "        print(\"User : \" + user_input , file = Dfile) # output to file for later dialogue analysis\n",
        "\n",
        "        # Send user input to OpenAI API\n",
        "        response = chat_llm_chain.predict(human_input=user_input)\n",
        "\n",
        "        # Print bot response\n",
        "        print(str(i) + \" ChatBot : \" + response)\n",
        "        print(\"ChatBot : \" + response , file = Dfile) # output to file for later dialogue analysis\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Interrupted by user\")\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQTOkCIVgYJE"
      },
      "outputs": [],
      "source": [
        "# close the file where the dialogue is stored\n",
        "Dfile.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}